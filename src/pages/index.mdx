---
layout: ../layouts/Layout.astro
title: "SoFoNO : Arbitrary-Scale Image Super-Resolution via Sobolev Fourier Neural Operator"
conference: Neurocomputing'25
authors:
  - name: Jong Kwon Oh
    institution: Pohang University of Science and Technology
    notes: [1]
  - name: Hwijae Son
    institution: Konkuk University
    notes: ["1"]
  - name: Hyung Ju Hwang
    institution: Pohang University of Science and Technology
  - name: Jihyong Oh
    institution: Chung-Ang University
    notes: ["*"]
notes:
  - symbol : 1
    text: Co-first authors
  - symbol: "*"
    text: Corresponding Author
links:
  - name: Paper
    url: https://www.sciencedirect.com/science/article/pii/S0925231225026165
    icon: ri:file-pdf-2-line
  - name: Code
    url: https://github.com/JongKwonOh/SoFoNO?tab=readme-ov-file
    icon: ri:github-line
  - name: arXiv
    url: https://github.com/RomanHauksson/academic-project-astro-template
    icon: academicons:arxiv

theme: device
favicon: favicon.svg
description: Simple project page template for your research paper, built with Astro and Tailwind CSS
thumbnail: screenshot-light.png
---

import Video from "../components/Video.astro";
import HighlightedSection from "../components/HighlightedSection.astro";
import SmallCaps from "../components/SmallCaps.astro";
import Figure from "../components/Figure.astro";
import Picture from "../components/Picture.astro";
import ModelViewer from "../components/ModelViewer.astro"
import TwoColumns from "../components/TwoColumns.astro";
import YouTubeVideo from "../components/YouTubeVideo.astro";
import LaTeX from "../components/LaTeX.astro";
import { Comparison } from "../components/Comparison.tsx";

import DemoSwitcher from "../components/DemoSwitcher.tsx";
import Table from "../components/Table.astro";
export const components = { table: Table }

import am2 from "../assets/am2.png";
import cmlab from "../assets/cmlab.png";

import outside from "../assets/outside.mp4";
import transformer from "../assets/transformer.webp";
import graphical_abstract from "../assets/graphical_abstract.png"

import demo_1 from "../assets/demo_1.gif?url"

import input_x2 from "../assets/input_x2.png"
import output_x2 from "../assets/output_x2.png"
import input_x3 from "../assets/input_x3.png"
import output_x3 from "../assets/output_x3.png"
import input_x4 from "../assets/input_x4.png"
import output_x4 from "../assets/output_x4.png"
import input_x8 from "../assets/input_x8.png"
import output_x8 from "../assets/output_x8.png"

import div2k from "../assets/DIV2K_table.png"
import benchmark_table from "../assets/Benchmark_table.png"
import benchmark_table_1 from "../assets/Benchmark_table1.png"
import benchmark_table_2 from "../assets/Benchmark_table2.png"
import qualitative_result from "../assets/qualitative_result.png"
import qualitative_result_1 from "../assets/qualitative_result_1.png"
import qualitative_result_2 from "../assets/qualitative_result_2.png"

import motivation from "../assets/motivation.png?url"
import plot from "../assets/plot_s.png"
import freq from "../assets/frequency_comparison.png"

<br />

**_TL;DR — We present Sobolev Fourier Neural Operator (SoFoNO) that learns Sobolev exponents to enhance frequency-domain detail reconstruction, achieving more realistic arbitrary-scale super-resolution without attention._**

<div class="mx-auto max-w-[65rem] px-6 rounded-xl bg-zinc-100 dark:bg-zinc-800">
  <HighlightedSection>
  
  ## Abstract

  Accurately reconstructing fine textures and sharp edges remains a significant challenge in Single Image Super-Resolution (SISR) tasks, often resulting in overly smooth and less realistic images.
  To alleviate this issue we propose a novel SISR framework named Sobolev Fourier Neural Operator (SoFoNO).
  Central to our approach is a specialized architecture featuring a Sobolev Branch, which effectively captures detailed structures in the frequency domain via a learnable Sobolev exponent.
  Importantly, the learned Sobolev exponent is directly employed as derivative order parameters within the Sobolev loss function, enabling more precise and visually coherent reconstructions.
  Unlike conventional pixel-level loss functions, the Sobolev loss explicitly incorporates frequency-domain penalties, significantly enhancing the reconstruction quality of detailed image structures.
  Extensive experiments conducted on multiple datasets under both in-scale and out-scale scenarios demonstrate that our SoFoNO provides robust and effective performance in arbitrary-scale super-resolution, consistently outperforming representative existing methods across various tested scale factors without relying on attention mechanisms.

  </HighlightedSection>
</div>

## Demo

<div class="flex flex-col items-center my-6 space-y-3 not-prose">
  <p class="text-center text-lg font-bold text-gray-800 dark:text-gray-200">
    <span>Upscaling factor ×4</span>  <br /> <br />
    <span>Input</span>
    <span class="inline-block mx-45"> </span>
    <span>Output</span>
  </p>
  <img src={demo_1} alt="Demo animation" width="800" class="rounded-xl shadow-md" />
</div>



<DemoSwitcher
  client:idle
  pairs={[
    {
      leftSrc: input_x2.src ?? input_x2,
      rightSrc: output_x2.src ?? output_x2,
      leftAlt: "Input 1 (degraded)",
      rightAlt: "Output 1 (restored)",
      label: "Upscaling factor : ×2"
    },
    {
      leftSrc: input_x3.src ?? input_x3,
      rightSrc: output_x3.src ?? output_x3,
      leftAlt: "Input 2 (degraded)",
      rightAlt: "Output 2 (restored)",
      label: "Upscaling factor : ×3"
    },
    {
      leftSrc: input_x4.src ?? input_x4,
      rightSrc: output_x4.src ?? output_x4,
      leftAlt: "Input 3 (degraded)",
      rightAlt: "Output 3 (restored)",
      label: "Upscaling factor : ×4"
    },
    {
      leftSrc: input_x8.src ?? input_x8,
      rightSrc: output_x8.src ?? output_x8,
      leftAlt: "Input 4 (degraded)",
      rightAlt: "Output 4 (restored)",
      label: "Upscaling factor : ×8"
    }
  ]}
/>

## Motivation 
We utilize a practical approximation method, regardless of whether <LaTeX inline>{String.raw`s \in \mathbb{N}`}</LaTeX>.
The equation is as follows:

<LaTeX>
{String.raw`\begin{equation}
\Vert f \Vert_{H^s}^2 \approx \Vert \mathcal{F}^{-1}\!\big((1+\Vert \xi \Vert^2)^{s/2}\,\mathcal{F}(f)\big)\Vert_{L^2}^2 \,,
\end{equation}`}
</LaTeX>

where <LaTeX inline>{String.raw`\xi`}</LaTeX> represents the frequency domain variable, 
<LaTeX inline>{String.raw`\mathcal{F}`}</LaTeX> and <LaTeX inline>{String.raw`\mathcal{F}^{-1}`}</LaTeX> denote the Fast Fourier Transform (FFT) and the Inverse Fast Fourier Transform (IFFT), respectively, and 
<LaTeX inline>{String.raw`s \in \mathbb{R}`}</LaTeX> represents the derivative order. 

<div class="flex justify-center my-8 not-prose">
  <img
    src={motivation}
    alt="Motivation figure"
    width="1000"
    class="rounded-xl shadow-md"
  />
</div>

We introduce a learnable Sobolev exponent s that directly controls frequency emphasis in the transformation. 
When s&nbsp;&gt;&nbsp;0, high-frequency components are amplified, resulting in sharper, whereas s&nbsp;&lt;&nbsp;0 enhances low-frequency components, producing smoother outputs.

## Architecture

The proposed SoFoNO architecture consists of three main stages: Encoder, SoFoNO Blocks, and Decoder.

<div class="bg-white inline-block px-5 rounded-xl">
  <Figure>
    <Picture
      slot="figure"
      src={graphical_abstract}
      alt="Overall Architecture of SoFoNO."
    />
    <Fragment slot="caption">
      Overall Architecture of SoFoNO.
    </Fragment>
  </Figure>
</div>

First, a low-resolution (LR) image is processed by an EDSR encoder to produce deep feature maps that capture local texture information. 
Then, a Local Ensemble module performs arbitrary-scale upsampling by aggregating nearby latent features with their relative coordinates, enabling flexible resolution synthesis. 
These features are fed into a sequence of **SoFoNO Blocks**, each containing two parallel branches: a **Local Branch** that refines spatial details and a **Sobolev Branch** that operates in the frequency domain to emphasize high-frequency components using a learnable Sobolev exponent. 
The two branches are adaptively fused through **Cross-Mixing** and AdaIN operations to effectively integrate spatial and spectral information. 
Finally, the Decoder reconstructs the high-resolution image through lightweight convolutional layers and bilinear interpolation, while a combined real- and frequency-domain loss ensures balanced optimization.

## Results

### Quantitative Results

<div class="flex flex-col items-center gap-8">
  <div class="bg-white inline-block px-5 rounded-xl w-[600px]">
    <Figure>
      <Picture
        slot="figure"
        src={div2k}
        alt="DIV2K Dataset Benchmark Table"
        class="w-full"
      />
      <Fragment slot="caption">
        Results on the DIV2K validation set.
      </Fragment>
    </Figure>
  </div>

  <div class="bg-white inline-block px-5 rounded-xl w-[800px]">
    <Figure>
      <Picture
        slot="figure"
        src={benchmark_table}
        alt="Benchmark Table"
      />
      <Fragment slot="caption">
        Results on the Benchmark datasets.
      </Fragment>
    </Figure>
  </div>
</div>

SoFoNO demonstrates consistently superior performance across various datasets.
It achieves outstanding results on the **DIV2K validation set** and maintains high performance on multiple **benchmark datasets**, including Set5, Set14, B100, and Urban100. 
These results highlight SoFoNO’s strong generalization ability and its effectiveness in producing high-quality, detail-preserving reconstructions across diverse image domains.

### Qualitative Results

<div class="flex flex-wrap justify-center gap-8">
  <div class="bg-white inline-block px-5 rounded-xl max-w-[28rem]">
    <Figure>
      <Picture slot="figure" src={qualitative_result_1} alt="Qualitative Results 1" />
      <Fragment slot="caption">Qualitative Results (Upscaling factor&nbsp;:&nbsp;&times;4)</Fragment>
    </Figure>
  </div>

  <div class="bg-white inline-block px-5 rounded-xl max-w-[28rem]">
    <Figure>
      <Picture slot="figure" src={qualitative_result_2} alt="Qualitative Results 2" />
      <Fragment slot="caption">Qualitative Results (Upscaling factor&nbsp;:&nbsp;&times;10)</Fragment>
    </Figure>
  </div>
</div>

SoFoNO demonstrates remarkable visual fidelity. 
The left panel (×4) shows SoFoNO’s ability to accurately reconstruct fine textures and structural patterns, preserving high-frequency details with exceptional clarity at **in-scale**.
In contrast, the right panel (×10) highlights its robustness under **out-scale** conditions, where conventional methods often fail. 
SoFoNO faithfully restores complex structures like ceiling textures, maintaining both texture coherence and geometric consistency.

## Analysis

During training, the learnable Sobolev exponent s initially takes negative values, indicating a focus on low-frequency, coarse structures.
As training progresses, s gradually increases and becomes positive, shifting the model’s emphasis toward high-frequency details and resulting in sharper, more refined reconstructions.

<div class="flex flex-col items-center gap-8">

  <div class="bg-white inline-block px-5 rounded-xl w-[700px]">
    <Figure>
      <Picture
        slot="figure"
        src={plot}
        alt="Training dynamics of Sobolev exponent"
        class="rounded-lg w-full"
      />
      <Fragment slot="caption">
        Convergence trend of parameter s in SoFoNO during training.
      </Fragment>
    </Figure>
  </div>

  <div class="bg-white inline-block px-5 rounded-xl w-[900px] shadow-md">
    <Figure>
      <Picture
        slot="figure"
        src={freq}
        alt="Frequency emphasis visualization"
        class="rounded-lg w-full"
      />
      <Fragment slot="caption">
        <span class="text-gray-600 dark:text-gray-400">
          Reconstructed image (x7) patches (left) and corresponding frequency error maps (right) for different values of s.
        </span>
      </Fragment>
    </Figure>
  </div>

</div>


## BibTeX citation

```bibtex
@article{oh2025sofono,
  title={SoFoNO: Arbitrary-scale image super-resolution via Sobolev Fourier neural operator},
  author={Oh, Jong Kwon and Son, Hwijae and Hwang, Hyung Ju and Oh, Jihyong},
  journal={Neurocomputing},
  pages={131944},
  year={2025},
  publisher={Elsevier}
}
